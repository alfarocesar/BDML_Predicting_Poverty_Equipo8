\documentclass[12pt,a4paper,onecolumn]{article}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PAQUETES
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\usepackage[margin=1in]{geometry}
\usepackage{authblk}
\usepackage[utf8]{inputenc}  % UTF-8 evita problemas de caracteres
\usepackage[T1]{fontenc}     % Mejor soporte de fuentes en LaTeX
\usepackage[spanish]{babel}  % Manejo correcto de idioma español
\usepackage{amsfonts}
\usepackage{graphicx} % Necesario para incluir imágenes
\usepackage{xcolor}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[table]{xcolor}
\usepackage{setspace}
\usepackage{booktabs}
\usepackage{dcolumn}
\usepackage{rotating}
\usepackage{threeparttable}
\usepackage[capposition=top]{floatrow}
\usepackage[labelsep=period]{caption}
\usepackage{subcaption}
\usepackage{multicol}
\usepackage[bottom]{footmisc}
\usepackage{enumerate}
\usepackage{units}
\usepackage{placeins}
\usepackage{booktabs,multirow}
\usepackage{float}
\usepackage{pdflscape}      % Para landscape completo
\usepackage{lscape}         % Alternativa si pdflscape da problemas
\usepackage{longtable}      % Para tablas que ocupan más de una página
\usepackage{geometry}       % Para ajustar márgenes si es necesario

% Bibliografía
\usepackage{natbib}
\bibliographystyle{apalike}
\bibpunct{(}{)}{,}{a}{,}{,}

% Formato de párrafos
\renewcommand{\baselinestretch}{1}

% Definir columnas para tablas
\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

\usepackage{xfrac}
\usepackage{bbold}

\setcounter{secnumdepth}{6}

\usepackage{titlesec}
\titleformat*{\subsection}{\normalsize \bfseries}

\usepackage[colorlinks=true,linkcolor=black,urlcolor=blue,citecolor=blue]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     TÍTULO, AUTORES Y FECHA              %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{\textbf{Taller 2 - Predicción de Pobreza en Colombia}}

\author{%
\begin{center}
Harold Stiven Acuña\\
José David Cuervo\\
José David Dávila\\
César Augusto Alfaro
\end{center}%
}

\date{\today}

% Configuración simple para espaciado de párrafos
\setlength{\parskip}{0.6em} % Espacio entre párrafos
\setlength{\parindent}{1em} % Sangría moderada

\begin{document}

\maketitle
\thispagestyle{empty}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ABSTRACT
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{abstract}
Este documento presenta el análisis de datos y la implementación de modelos de clasificación para la predicción de la pobreza en Colombia.
\end{abstract}

\medskip

\begin{flushleft}
    {\bf Palabras clave:} pobreza, clasificación, aprendizaje automático \\
    {\bf Clasificación JEL:} J31, C53, J16
\end{flushleft}

% Añadir información del repositorio GitHub
\begin{center}
    \textit{Repositorio GitHub:} \url{https://github.com/alfarocesar/BDML_Predicting_Poverty_Equipo8}
\end{center}

\pagebreak
\singlespacing
\setlength{\parindent}{0pt}
\setlength{\parskip}{1em}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%           DOCUMENTO                       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introducción}

La migración del campo a la ciudad, producto de la Primera y Segunda Revolución Industrial, trajo consigo un aumento significativo de la población, así como conflictos de orden político, económico y social, en igual medida para todos los países que decidieron sumarse a dicho proceso de transformación emergente, como Gran Bretaña, Francia, Alemania, Estados Unidos, entre otros. Es así como la pobreza, como concepto abstracto y simbólico, se introduce en la discusión del mundo científico, mismo que se encontraba en auge, no solo para las ciencias exactas que derivan de las leyes de la física, sino también en ciencias cuyo objeto de estudio resultaba más abstracto y retador, aún en nuestros tiempos: la sociedad.

La pobreza, entonces, generó la inminente necesidad de ser considerada, sobre todo, para encontrar formas de medición acertadas. La razón de ser de ello es muy sencilla: a medida que la sociedad avanzaba, el discurso de los derechos se hizo más fuerte; la dignidad, el mínimo vital, el contrato social, entre otros, se hicieron vigentes y, en consecuencia, la pobreza se convirtió en objeto de estudio, con el propósito de determinar su existencia, evolución y distribución.

En este punto, la medición de la pobreza adquiere especial relevancia y su análisis, con el paso del tiempo, ha incluido inferencia, teoría, estadística, abstracción, idealización, predicción, cálculo y construcción de instrumentos \cite{tal2016measuring}. Sin embargo, aún falta teoría y una estructura definida que permita a los investigadores concluir que determinada asignación numérica representa adecuadamente la característica de la pobreza que se pretende medir \cite{huffman2024measurement}.

Amartya Sen señala que la pobreza se mide no solo frente a la falta de ingresos y recursos, sino también en la falta de capacidades que restringen las opciones y oportunidades de las personas. Así las cosas, sobrevienen dos dificultades hasta el momento: la falta de una estructura para medir la pobreza y la determinación de las características que representan dicha pobreza.

Una medición precisa, eficiente y oportuna de la pobreza es clave para diseñar políticas públicas que sean no solo efectivas, sino también costo-eficientes. Sin embargo, los métodos tradicionales de medición —basados en encuestas extensas— implican altos costos y tiempos prolongados de recolección, procesamiento y análisis. En respuesta a esta limitación, el uso de técnicas de \textit{machine learning} ofrece una alternativa prometedora: construir modelos que permitan predecir la condición de pobreza de los hogares utilizando un número reducido de variables y, en consecuencia, realizar evaluaciones más rápidas y baratas.

Este proyecto busca desarrollar modelos de clasificación binaria que permitan identificar si un hogar colombiano se encuentra en condición de pobreza, utilizando microdatos del DANE y la Misión MESE, a nivel de hogar e individuo. La Figura~\ref{fig:pobreza_colombia} ilustra la evolución reciente de la pobreza en el país, motivando así la necesidad de mejorar las herramientas de diagnóstico.

\begin{figure}[H]
  \centering
  \includegraphics[width=0.85\textwidth]{../views/figures/pobreza_colombia.png}
  \caption{Evolución reciente de la pobreza monetaria en Colombia.}
  \label{fig:pobreza_colombia}
\end{figure}

A lo largo del documento se evalúan diferentes algoritmos de clasificación (como regresión logística, árboles de decisión, random forest, entre otros) y se presenta una comparación sistemática de su desempeño. El modelo con mejor rendimiento logró una puntuación F1 de \textbf{[0.5686]}, utilizando solo \textbf{[número]} variables, lo que representa un avance en términos de precisión y simplicidad. Este modelo fue seleccionado como la base para las predicciones entregadas en Kaggle.

Además de identificar el mejor algoritmo, se discute la importancia relativa de las variables predictoras, destacando aquellas con mayor capacidad explicativa. Estos hallazgos permiten no solo mejorar la focalización de políticas sociales, sino también abrir camino para sistemas de monitoreo más ágiles y adaptativos.

\section{Datos}
\subsection{Adecuación de los datos}

Los datos utilizados en este estudio provienen de DANE y la misión "Empalme de las Series de Empleo, Pobreza y Desigualdad (MESE)". Estos datos son adecuados para resolver el problema de predicción de pobreza por varias razones. Primero, contienen información detallada a nivel de hogar e individuo, lo que permite capturar la heterogeneidad socioeconómica de la población colombiana. Segundo, incluyen la variable objetivo de interés (Pobre) que está correctamente definida según el criterio oficial del DANE: un hogar es clasificado como pobre si su ingreso per cápita es menor a la línea de pobreza establecida. Tercero, contienen variables sobre composición demográfica, características laborales, educativas y de vivienda que son teóricamente relevantes para explicar la pobreza.

Para este análisis, disponemos de cuatro conjuntos de datos divididos en entrenamiento y prueba a nivel de hogar e individuo: \texttt{train\_hogares.csv}, \texttt{train\_personas.csv}, \texttt{test\_hogares.csv} y \texttt{test\_personas.csv}. Esta división permite realizar predicciones fuera de muestra, lo que representa un desafío adicional ya que algunas variables presentes en los datos de entrenamiento están ausentes en los de prueba, simulando un escenario real donde no toda la información está disponible al momento de realizar predicciones.

Verificamos que la variable objetivo \textit{Pobre} esté correctamente definida siguiendo la metodología del DANE, mediante la comparación con cálculos propios:

\begin{equation}
\text{Pobre} = I(\text{Ingpcug} < \text{Lp})
\end{equation}

Al realizar esta validación, obtuvimos una coincidencia del 100\% con la variable original, confirmando su correcta definición. La distribución de la variable objetivo reveló un desbalance importante: el 80\% de los hogares se clasifican como no pobres, mientras que el 20\% son considerados pobres, lo que requirió estrategias específicas durante el modelamiento.

{\color{blue} Incluir tabla: Distribución de la Variable Objetivo (Pobreza)}

\subsection{Construcción de la muestra}

El proceso de construcción de la muestra involucró varios pasos clave para garantizar datos limpios y adecuados para el modelamiento:

\subsubsection{Análisis de la base train\_hogares y comparación con test\_hogares}

Se inició el trabajo con una revisión detallada de las variables disponibles en la base de entrenamiento de hogares (\texttt{train\_hogares}), comparándolas con las de la base de prueba (\texttt{test\_hogares}). Este paso fue crucial para identificar variables que, al estar ausentes en la prueba, debían eliminarse del análisis o de la base consolidada. En particular, se eliminaron las siguientes variables porque contenían información directa del ingreso o porque solo existían en la base de entrenamiento:

\texttt{Ingtotug, Ingtotugarr, Ingpcug, Indigente, Npobres, Nindigentes}

Estas variables, aunque relevantes, no estaban disponibles para predicción en la base de prueba, por lo tanto, su inclusión habría implicado una filtración de información inadecuada. Además, se eliminaron variables que no aportan al análisis predictivo como:

\texttt{Directorio, Secuencia\_p, Mes, P5130, Fex\_c, Fex\_dpto}

Las variables \texttt{P5100} y \texttt{P5140} fueron tratadas como gastos que pueden legítimamente tomar valor cero, por lo cual los valores faltantes se imputaron con ceros.

\subsubsection{Análisis de la base train\_personas y comparación con test\_personas}

Se realizó una limpieza similar en las bases de individuos. Se eliminaron variables que no están disponibles en ambas bases o que no describen características estables del hogar. En este grupo se encuentran identificadores (\texttt{Directorio, Secuencia\_p}), variables temporales (\texttt{Mes}), ponderadores (\texttt{Fex\_c, Fex\_dpto}) y una lista extensa de variables relacionadas con ingresos individuales, que no están disponibles en la base de prueba.

Además, se excluyeron variables que no aportaban valor predictivo directo a nivel hogar, como \texttt{Orden}. Para las variables categóricas binarias que solo tomaban valores 1 y NA (como \texttt{Pet, Oc, Des, Ina}), los valores faltantes fueron transformados en ceros, con el fin de estandarizar su uso en los conteos que alimentan la base de hogares.

\subsubsection{Construcción de nuevas variables para consolidar la base de hogares}

Utilizamos la variable \texttt{id} como clave para unir las bases de datos de hogares e individuos. Sin embargo, esto requirió un paso previo de agregación para transformar la información a nivel de individuos en variables a nivel de hogar:

\begin{itemize}
    \item \textbf{Conteos:} Se contó el número de miembros que cumplían ciertas condiciones (por ejemplo, número de ocupados, hombres, mujeres, menores de edad, personas en edad de trabajar, desocupados e inactivos).
    \item \textbf{Proporciones:} Para variables categóricas como afiliación a seguridad social (\texttt{P6090}) o deseo de más horas (\texttt{P6240}), se calcularon proporciones sobre el total de personas en edad de trabajar (\texttt{Pet = 1}).
    \item \textbf{Estadísticas demográficas:} Se calcularon edad promedio, máximo nivel educativo en el hogar, promedio de horas trabajadas usando variables como \texttt{P6040}, \texttt{P6210s1} y \texttt{P6800}.
    \item \textbf{Indicadores de seguridad social:} Proporción de afiliados, cotización a pensión.
    \item \textbf{Características laborales:} Proporciones por tipo de ocupación, tamaño de empresa, actividades adicionales.
    \item \textbf{Características específicas del jefe de hogar:} Edad, sexo, nivel educativo y situación laboral.
\end{itemize}

Esta agregación nos permitió generar 37 nuevas variables derivadas que capturan la estructura y características socioeconómicas del hogar, enriqueciendo significativamente el conjunto de datos. El enfoque utilizado garantiza que las variables incorporadas describan características estructurales del hogar y puedan ser calculadas en la base de prueba, utilizando únicamente la información disponible en ambas bases.

\subsection{Limpieza de datos y tratamiento de valores faltantes}

El análisis de valores faltantes reveló patrones importantes:

\begin{itemize}
    \item La mayoría de variables tienen menos del 15\% de valores faltantes, siendo procesables con técnicas de imputación.
    \item Identificamos variables con alta proporción de valores faltantes (>33\%) como \texttt{jefe\_tiempo\_trabajo} y varias proporciones de características específicas que fueron candidatas a eliminación.
    \item Las variables relacionadas con ingresos complementarios presentaban patrones de valores faltantes no aleatorios, siendo más frecuentes en hogares no pobres.
\end{itemize}

Como parte de la limpieza, se eliminaron variables con más del 33\% de valores faltantes en la base consolidada. Esta decisión se basó en las buenas prácticas revisadas en clase y en los tutoriales de preprocesamiento de datos.

Para las variables restantes con valores faltantes, se adoptaron las siguientes estrategias:

\begin{itemize}
    \item \textbf{Imputación con la mediana:} Para variables numéricas como \texttt{promedio\_horas\_trab}, \texttt{prop\_cotiza\_pension}, \texttt{prop\_actividad\_adicional} y \texttt{prop\_desea\_mas\_horas}, se imputó la mediana dentro de cada base (train o test).
    \item \textbf{Imputación con la moda:} Variables categóricas como \texttt{max\_nivel\_educativo} y discretas como \texttt{max\_años\_educ} fueron imputadas con su moda, debido a su naturaleza y su importancia como predictores.
    \item \textbf{Para variables como \texttt{prop\_afiliados\_ss} y \texttt{prop\_busca\_trabajo}:} También se utilizó la mediana para la imputación.
\end{itemize}

Estas decisiones fueron implementadas en el script \texttt{03\_data\_cleaning\_Fast.R}.

\subsubsection{Manejo de variables categóricas}

Un análisis especial se realizó para la variable \texttt{Oficio}, que presentaba más de 80 categorías diferentes. Mediante un análisis de asociación con la variable objetivo, agrupamos los oficios en tres categorías según su relación con la pobreza:
\begin{itemize}
    \item \textbf{Grupo 1:} Oficios con baja tasa de pobreza (promedio 17\%)
    \item \textbf{Grupo 2:} Oficios con tasa media de pobreza (promedio 37\%)
    \item \textbf{Grupo 3:} Oficios con alta tasa de pobreza (promedio 59\%)
\end{itemize}

Esta agrupación simplificó el modelamiento y mejoró la interpretabilidad manteniendo la relevancia predictiva.

\subsection{Análisis descriptivo}

\subsubsection{Distribución de la pobreza}

La variable objetivo presenta un desbalance notable: el 79.9\% de los hogares se clasifican como no pobres y el 20.1\% como pobres, con un ratio de desbalance de aproximadamente 4:1.

{\color{blue} Incluir tabla: Distribución de la Variable Objetivo (Pobreza)}

\subsubsection{Características por estado de pobreza}

El análisis reveló diferencias significativas entre hogares pobres y no pobres:

{\color{blue} Incluir figura: Distribución de horas trabajadas por estado de pobreza}

Los hogares pobres tienden a reportar menos horas trabajadas en promedio, lo que se relaciona con condiciones laborales más precarias y menor estabilidad en el empleo.

Encontramos variables altamente correlacionadas con la pobreza, destacando:
\begin{itemize}
    \item \textbf{Negativas (menor valor asociado a mayor pobreza):} Proporción de cotizantes a pensión (-0.51), proporción de trabajadores en empresas grandes (-0.47), y máximo nivel educativo (-0.39).
    \item \textbf{Positivas (mayor valor asociado a mayor pobreza):} Proporción de oficios del grupo 3 (0.43), número de menores (0.37) y proporción de inactivos (0.31).
\end{itemize}

{\color{blue} Incluir figura: Variables con mayor correlación con la pobreza}

Este análisis de correlaciones ayudó a identificar las variables más relevantes para la predicción, permitiéndonos crear un conjunto parsimonioso y predictivo.

\subsubsection{Importancia de la composición familiar y laboral}

El análisis chi-cuadrado para variables categóricas reveló asociaciones significativas entre pobreza y diversas características:

\begin{itemize}
    \item La presencia de jefes de hogar ocupados reduce significativamente la probabilidad de pobreza (V de Cramér = 0.23)
    \item Los hogares con mayor proporción de miembros en oficios del grupo 3 (alta tasa de pobreza) tienen mayor probabilidad de ser pobres (V de Cramér = 0.31)
    \item El nivel educativo del jefe de hogar muestra una fuerte asociación con la pobreza (V de Cramér = 0.27)
\end{itemize}

Estos hallazgos confirman la importancia de variables relacionadas con capital humano, estructura familiar y características laborales para predecir la pobreza.

\subsection{Justificación de la selección de variables}

La selección final de variables para nuestros modelos se basó en tres criterios principales:

\begin{enumerate}
    \item \textbf{Relevancia predictiva:} Utilizamos correlaciones con la variable objetivo y pruebas chi-cuadrado para identificar las variables más predictivas.
    \item \textbf{Disponibilidad en datos de prueba:} Garantizamos que todas las variables seleccionadas estuvieran disponibles tanto en el conjunto de entrenamiento como en el de prueba.
    \item \textbf{Parsimonia:} Buscamos un conjunto mínimo de variables que maximizara el poder predictivo.
\end{enumerate}

Eliminamos variables con más del 33\% de valores faltantes y aquellas con alta redundancia (correlacionadas entre sí a más de 0.7). Para variables con correlación alta, mantuvimos la que presentaba mayor asociación con la variable objetivo.

En el caso de variables categóricas como la ocupación, optamos por transformaciones que preservaran su poder predictivo al tiempo que simplificaban el modelamiento (agrupación en 3 categorías).

Las variables finales incluyeron:
\begin{itemize}
    \item \textbf{Características del hogar:} Número de miembros, relación de dependencia, proporción de ocupados.
    \item \textbf{Capital humano:} Nivel educativo máximo y del jefe de hogar, proporción de afiliados a seguridad social.
    \item \textbf{Características laborales:} Distribución por grupos de ocupación, horas trabajadas, tamaño de empresa.
    \item \textbf{Características del jefe de hogar:} Sexo, edad, ocupación.
    \item \textbf{Vivienda y ubicación:} Características de la vivienda, departamento.
\end{itemize}

El flujo de trabajo seguido en esta etapa responde a varios objetivos:

\begin{itemize}
    \item \textbf{Evitar fuga de información:} Se eliminaron variables disponibles solo en el entrenamiento.
    \item \textbf{Garantizar la coherencia entre bases:} Se preservaron únicamente las variables comunes entre train y test.
    \item \textbf{Convertir la información individual en predictores agregados:} Esto permite maximizar el uso de la información disponible sin violar las restricciones impuestas por la estructura del problema.
    \item \textbf{Preparar una base limpia y funcional para modelado:} Las bases \texttt{train\_cleaned.csv} y \texttt{test\_cleaned.csv} contienen las variables seleccionadas e imputadas, listas para el entrenamiento de modelos.
\end{itemize}

Este conjunto final de variables balanceó el poder predictivo, la disponibilidad en los datos de prueba y la parsimonia, permitiéndonos construir modelos robustos y generalizables para la predicción de pobreza.

\subsection{Análisis descriptivo}
Exploración de la variabilidad de los datos con tablas y gráficos.

\section{Modelos y Resultados}

\subsection{Modelo de Selección y Entrenamiento}

\subsubsection{Metodología}

\paragraph{1. Regresión Logística}

Esta primera metodología estima la probabilidad de que una observación pertenezca a una clase (por ejemplo, "pobre" como en este caso) en función de una combinación lineal de las variables independientes. Esta combinación se transforma usando la función de distribución de probabilidad logística, lo que garantiza que los valores estimados estén entre 0 y 1. Aunque no tiene muchos hiperparámetros, en este trabajo se utilizó la metodología de validación cruzada para ajustar el umbral de clasificación (por ejemplo, elegir si se clasifica como "pobre" cuando la probabilidad es mayor a 0.5 o a otro valor), además de evaluar su capacidad predictiva comparado con modelos más complejos. La forma funcional básico de dicho modelo es:

$$P\left( y = 1 \middle| X \right) = \frac{1}{1 + e^{- (\beta_{0} + \beta_{1 + \ldots + \beta_{k}})}}$$

\paragraph{2. Elastic Net}

Este modelo es una variante penalizada de la regresión logística que incluye regularización mediante una combinación de Lasso (penalización L1) y Ridge (penalización L2). Es útil cuando hay muchas variables correlacionadas o cuando se busca reducir el número de variables relevantes. Los hiperparámetros clave son lambda (intensidad de la penalización) y alpha (mezcla entre L1 y L2). Ambos se seleccionaron con validación cruzada, evaluando el rendimiento del modelo en diferentes combinaciones para elegir la más adecuada. La forma funcional de este modelo es:

$$LOSS = - \log(\beta) + \rho( \propto \sum_{}^{}\left| \beta_{j} \right| + (1 - \propto )\sum_{}^{}\beta_{j}^{2})$$

\paragraph{3. Árboles de Clasificación (CART)}

Este método construye un árbol de decisión dividiendo el conjunto de datos en subconjuntos más homogéneos según los valores de las variables. En cada nodo, el esta metodologia selecciona la variable y el punto de corte que maximizan la separación entre clases. Aunque es muy fácil de interpretar, un solo árbol puede sobreajustarse a los datos si es muy profundo o si se permite dividir con pocos datos. Por eso, se utilizó validación cruzada para determinar la profundidad óptima del árbol, el número mínimo de observaciones por nodo y el parámetro de complejidad que regula la poda del árbol.

\paragraph{4. GBM (Gradient Boosting Machines)}

GBM (Gradient Boosting Machines) es una técnica avanzada de Boosting utilizada para mejorar la precisión de los modelos predictivos, especialmente en problemas de clasificación y regresión. A diferencia de los métodos tradicionales de Boosting, GBM utiliza el gradiente descendente para minimizar la función de error, lo que permite que el modelo ajuste las predicciones de manera más eficiente.

\paragraph{5. Naive Bayes}

Naive Bayes es un clasificador probabilístico basado en el teorema de Bayes, que asume independencia condicional entre las variables predictoras. Aunque esta suposición es bastante fuerte, el modelo suele funcionar sorprendentemente bien en la práctica, especialmente cuando las variables tienen efectos independientes. No requiere un ajuste intensivo de hiperparámetros, pero aun así se utilizó validación cruzada para evaluar su desempeño y compararlo con los otros modelos. Para calcular dichas probabilidades de pertenecer a una clase u otra se utiliza la siguiente formula:

$$P\left( Y \middle| X_{1},X_{2},\ldots,X_{k} \right) = P(Y)\prod_{}^{}{P(X_{J}|Y)}$$

Donde esto es posible dado el supuesto de independencias de las variables.

\subsubsection{Variables utilizadas}
A continuación se presentan las principales variables utilizadas en los modelos, como se puede observar en la Tabla \ref{tab:03_variables_modelos} del Anexo 3.

\subsection{Resultados}

A continuación se presentan los principales resultados con las metodologías anteriormente explicas, cabe resaltar que al ser una muestra de la población presenta un desbalance entre clases, pero afortunamente los mismos microdatos ayudan a resolver esto mediante un factor de expansión que no es mas que pesos muestrales que ayudan a corregir este problema.

Los resultados de la Tabla \ref{tab:04_tabla_logit} del Anexo 4 corresponden a las estimaciones del modelo Logit, los resultados muestran que variables como el hacinamiento, pertenecer al régimen subsidiado de salud y trabajar en empresas pequeñas están asociadas positivamente con la probabilidad de ser pobre, mientras que contar con educación, estar trabajando, cotizar a pensión y ser pensionado reducen significativamente dicha probabilidad. Por ejemplo, cotizar a pensión o tener mayor nivel educativo parece ser un factor protector frente a la pobreza, mientras que vivir en condiciones de hacinamiento o depender de subsidios refleja situaciones de vulnerabilidad estos resultados hay que interpretarlos de manera cuidadosa ya que no necesariamente representan una relación causal. Algunos coeficientes presentan magnitudes muy elevadas (como los de TGP o CotizaPension), lo cual puede estar relacionado con problemas de escalamiento o multicolinealidad, especialmente dado el tamaño de la muestra. A pesar de ello, la mayoría de las variables son altamente significativas y la reducción en la varianza residual sugiere que el modelo tiene un buen ajuste en comparación con uno sin predictores.

Los resultados de la Tabla \ref{tab:05_tabla_1_cart} del Anexo 5 corresponden a la metodología CARTs, resultados muestran que, en promedio, el modelo alcanzó una precisión del 81.5\% con una desviación estándar baja (0.17\%), lo que sugiere que el modelo es bastante estable entre las diferentes particiones de la muestra. El coeficiente Kappa, que mide la concordancia ajustada por azar, tuvo un valor medio de 0.47, lo cual indica un nivel de acierto moderado entre las predicciones del modelo y la realidad. A pesar de que los valores máximos de precisión alcanzaron hasta 83.4\% y el Kappa llegó a 0.54, los valores mínimos fueron cercanos al 81.2\% y 0.46, lo que sugiere que el modelo no presenta grandes variaciones entre distintas configuraciones que dicha metodología contempló. Estos resultados indican que el árbol de decisión logró capturar patrones relevantes para predecir la pobreza con un buen nivel de precisión.. Una aclaración importe es que este fue el único modelo que se estimo con todas las variables, el resto fueron estimados siguiendo otra especificación (Pobre \~ hacinamiento + r\_gast+ hacinamiento\_c + TGP +educ\_cab +trabajando +CotizaPension + Subsidiado + Pequena + Subsidios + CotizaPension + Pensionado + Ingresos\_AlquilerPensiones + OtrosIngresos) esto debido a que no todas las variables aportaban poder explicativo.

La Tabla \ref{tab:06_tabla_2_cart} del Anexo 6 representa otra estimación bajo metodología CARTS pero con otra especificación, también ajustado mediante validación cruzada, presenta resultados consistentes en cuanto a precisión y estabilidad. El valor promedio de precisión (Accuracy) fue de 81.2\%, con una desviación estándar baja (0.24\%), lo que indica que el modelo mantiene un rendimiento estable al aplicarse sobre distintas particiones de la muestra. El coeficiente de Kappa promedio fue de 0.46, lo cual representa un acuerdo moderado entre las predicciones del modelo y la clasificación real al igual que la especificación anterior. Aunque los valores máximos de precisión y Kappa alcanzaron 82.5\% y 0.50 respectivamente, los mínimos estuvieron en torno al 80.9\% y 0.45, lo que muestra que el rendimiento es bastante homogéneo a lo largo de los diferentes valores del hiperparámetro cp. En general, estos resultados refuerzan que el árbol de decisión logra capturar patrones relevantes para identificar condiciones de pobreza, aunque no presento grandes diferencias ante el cambio deespecificación.

La Tabla \ref{tab:07_tabla_elastic_net} del Anexo 7 por su parte utilizó la metodología de Elastic Net. Los resultados muestran una variabilidad en los valores de precisión (Accuracy) y Kappa en función de los hiperparámetros alpha y lambda. En promedio, la precisión del modelo fue de 80.45\%, con una desviación estándar de 0.12\%, lo que sugiere que el rendimiento del modelo es relativamente consistente a través de las diferentes particiones de la muestra. A lo largo del rango de alpha (que varió de 0.10 a 1.00) y lambda (desde 0.00017 hasta 0.13491), la precisión mostró poca variación, manteniéndose cercana al 81\% en los percentiles 1,2 y 3, lo que indica un buen ajuste del modelo. La tendencia en la precisión y el Kappa sugiere que la regularización aplicada por Elastic Net ayudó a controlar el sobreajuste sin perder mucho rendimiento, lo cual es positivo para problemas de alta dimensionalidad o multicolinealidad. En resumen, el modelo Elastic Net ofrece un buen balance entre precisión y estabilidad, con una capacidad moderada de clasificación, que es acorde a la magnitud de las variables involucradas.

La Tabla \ref{tab:08_tabla_naive_bayes} del Anexo 8 presenta los resultados del modelo ajustado por la metodología de Naive Bayes que fue ajustado con los hiperparámetros alpha y lambda. Los resultados indican que, en promedio, el modelo alcanzó una precisión (Accuracy) de 80.45\%, con una desviación estándar de 0.12\%, lo que indica una precisión bastante estable entre las particiones de la muestra. El coeficiente Kappa promedio fue de 0.38, la precisión se mantuvo relativamente constante, alcanzando un máximo de 81.31\% y un Kappa de 0.45. Los valores de precisión en el primer y tercer cuartil se mantienen alrededor de 80.7\% y 81.3\%, lo que sugiere que el modelo es robusto y no presenta grandes variaciones al ajustar los hiperparámetros. En cuanto a la desviación estándar de precisión, los valores son bajos, lo que refleja la estabilidad del modelo a través de las particiones de la muestra. En resumen, el modelo Naive Bayes parece ser efectivo para este conjunto de datos, logrando una buena precisión con una moderada capacidad de discriminación, y su rendimiento se mantiene estable a pesar de la variación en los hiperparámetros.

La Tabla \ref{tab:09_tabla_gbm} del Anexo 9 muestra las estimaciones del modelo mediante boosting, con los hiperparámetros shrinkage, interaction.depth, minobsinnode, y n.trees. Los resultados muestran una variabilidad en la precisión (Accuracy) y el coeficiente Kappa en función de los valores de los hiperparámetros. La precisión promedio fue de 78.86\%, con una desviación estándar baja (0.11\%). Al analizar los percentiles, la precisión alcanzó un máximo de 82.33\%, con un Kappa de 0.49 en el cuartil superior, lo que muestra que con valores de shrinkage y interaction.depth más altos, el modelo logra una mayor capacidad discriminativa. Por otro lado, los valores mínimos de precisión y Kappa fueron bastante bajos (74.86\% y 0.00, respectivamente), lo que refleja que con configuraciones subóptimas de los hiperparámetros, el modelo no logró un buen rendimiento. La mediana de precisión fue de 79.72\%, lo que indica que el modelo con una configuración intermedia de hiperparámetros proporciona un rendimiento razonablemente bueno y estable. Además, la desviación estándar de la precisión fue muy baja (cerca de 0.0004), lo que refuerza la estabilidad del modelo. En resumen, el modelo ajustado por boosting parece ser bastante efectivo, logrando buenos niveles de precisión y Kappa, especialmente con configuraciones más altas en los hiperparámetros shrinkage e interaction.depth, lo cual podría indicar que el modelo está aprovechando mejor las interacciones no lineales entre las variables.

\subsection{Matrices de Confusión}

A continuación, se presentan las matrices de confusión para los diferentes modelos evaluados:

En la Tabla \ref{tab:10_matriz_1_cart} del Anexo 10 se muestra la matriz de confusión para el primer modelo CART.

En la Tabla \ref{tab:11_matriz_2_cart} del Anexo 11 se presenta la matriz de confusión para el segundo modelo CART.

La Tabla \ref{tab:12_matriz_elastic_net} del Anexo 12 contiene la matriz de confusión para el modelo Elastic Net.

La matriz de confusión para el modelo de regresión logística se puede observar en la Tabla \ref{tab:13_matriz_logit} del Anexo 13.

Los resultados de la matriz de confusión para el modelo Naive Bayes se encuentran en la Tabla \ref{tab:14_matriz_naive_bayes} del Anexo 14.

Finalmente, la matriz de confusión para el modelo GBM se presenta en la Tabla \ref{tab:15_matriz_gbm} del Anexo 15.

\subsection{Importancia de Variables}

[Esta sección queda pendiente para incluir un análisis de la importancia relativa de las variables en los modelos]

\section{Conclusión}

Este estudio buscó estimar la pobreza utilizando técnicas de Big Data y algoritmos de aprendizaje automático aplicados con datos de “Empalme de las Series de Empleo, Pobreza y Desigualdad – MESE”. A pesar de las limitaciones inherentes al problema, se logró un desempeño razonable, alcanzando un F1-score de 0.56. El modelo con mejor rendimiento fue XGBoost, gracias a su capacidad para capturar relaciones no lineales y su potencia en términos de regularización y ajuste fino de parámetros \cite{huang2025unveiling}.
Uno de los principales aprendizajes de este ejercicio fue la estrategia utilizada para la imputación de datos faltantes. Se optó por imputar con la media en variables numéricas y con la moda en variables categóricas, una técnica sencilla de implementar, eficiente en términos computacionales y útil para mantener el tamaño original del conjunto de datos. Además, esta estrategia no altera la escala de las variables, lo que facilita la aplicación de diversos algoritmos de Machine Learning sin necesidad de ajustes adicionales.

El resultado obtenido también evidencia oportunidades de mejora significativas. Para incrementar la precisión del modelo y lograr métricas más robustas, es fundamental avanzar en la selección de variables más relevantes y explorar con mayor profundidad la sintonización de hiperparámetros. Como han señalado \cite{karmaker2025machine}, la identificación precisa de los determinantes socioeconómicos es clave para fortalecer la capacidad predictiva de los modelos de pobreza, especialmente en contextos donde los recursos y las políticas deben dirigirse de manera efectiva.

En conclusión, aunque los resultados obtenidos son alentadores, el desarrollo de modelos más precisos y accionables para la predicción de la pobreza requiere una combinación de mejoras técnicas, refinamiento metodológico.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% ANEXOS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\clearpage
\appendix
\section*{Anexos}
\addcontentsline{toc}{section}{Anexos}

\section{Estadísticas descriptivas de variables continuas}
\begin{table}[htbp]
\centering
\caption{Estadísticas descriptivas de variables continuas}
\label{tab:01_descriptiva_personas_continua}
\input{../views/tables/01_descriptiva_personas_continua.tex}
\end{table}

\section{Estadísticas descriptivas de variables discretas}
\begin{table}[htbp]
\centering
\caption{Estadísticas descriptivas de variables discretas}
\label{tab:02_descriptiva_personas_discreta}
\input{../views/tables/02_descriptiva_personas_discreta.tex}
\end{table}

\section{Variables utilizadas en los modelos}
\begin{table}[htbp]
\centering
\caption{Variables utilizadas en los modelos}
\label{tab:03_variables_modelos}
\input{../views/tables/03_variables_modelos.tex}
\end{table}

\section{Estimaciones mediante metodología LOGIT}
\begin{table}[htbp]
\centering
\caption{Estimaciones mediante metodología LOGIT}
\label{tab:04_tabla_logit}
\input{../views/tables/04_tabla_logit.tex}
\end{table}

\section{Estimación 1 metodología CARTs}
\begin{table}[htbp]
\centering
\caption{Estimación 1 metodología CARTs}
\label{tab:05_tabla_1_cart}
\input{../views/tables/05_tabla_1_cart.tex}
\end{table}

\section{Estimación 2 metodología CARTs}
\begin{table}[htbp]
\centering
\caption{Estimación 2 metodología CARTs}
\label{tab:06_tabla_2_cart}
\input{../views/tables/06_tabla_2_cart.tex}
\end{table}

\section{Estimaciones por Elastic Net}
\begin{table}[htbp]
\centering
\caption{Estimaciones por Elastic Net}
\label{tab:07_tabla_elastic_net}
\input{../views/tables/07_tabla_elastic_net.tex}
\end{table}

\section{Estimaciones por Naive Bayes}
\begin{table}[htbp]
\centering
\caption{Estimaciones por Naive Bayes}
\label{tab:08_tabla_naive_bayes}
\input{../views/tables/08_tabla_naive_bayes.tex}
\end{table}

\section{Estimaciones por GBM}
\begin{table}[htbp]
\centering
\caption{Estimaciones por GBM}
\label{tab:09_tabla_gbm}
\input{../views/tables/09_tabla_gbm.tex}
\end{table}

\section{Matriz de confusión - Modelo CART 1}
\begin{table}[htbp]
\centering
\caption{Matriz de confusión - Modelo CART 1}
\label{tab:10_matriz_1_cart}
\input{../views/tables/10_matriz_1_cart.tex}
\end{table}

\section{Matriz de confusión - Modelo CART 2}
\begin{table}[htbp]
\centering
\caption{Matriz de confusión - Modelo CART 2}
\label{tab:11_matriz_2_cart}
\input{../views/tables/11_matriz_2_cart.tex}
\end{table}

\section{Matriz de confusión - Modelo Elastic Net}
\begin{table}[htbp]
\centering
\caption{Matriz de confusión - Modelo Elastic Net}
\label{tab:12_matriz_elastic_net}
\input{../views/tables/12_matriz_elastic_net.tex}
\end{table}

\section{Matriz de confusión - Modelo Logit}
\begin{table}[htbp]
\centering
\caption{Matriz de confusión - Modelo Logit}
\label{tab:13_matriz_logit}
\input{../views/tables/13_matriz_logit.tex}
\end{table}

\section{Matriz de confusión - Modelo Naive Bayes}
\begin{table}[htbp]
\centering
\caption{Matriz de confusión - Modelo Naive Bayes}
\label{tab:14_matriz_naive_bayes}
\input{../views/tables/14_matriz_naive_bayes.tex}
\end{table}

\section{Matriz de confusión - Modelo GBM}
\begin{table}[htbp]
\centering
\caption{Matriz de confusión - Modelo GBM}
\label{tab:15_matriz_gbm}
\input{../views/tables/15_matriz_gbm.tex}
\end{table}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TERMINA EL CONTENIDO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\pagebreak
\singlespacing
\nocite{*}
\bibliographystyle{apalike}
\bibliography{references}
\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TERMINA EL DOCUMENTO
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
